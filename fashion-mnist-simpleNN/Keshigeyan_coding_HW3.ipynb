{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "## Fully connected neural net for FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective is to implement a neural network for FashionMNIST. \n",
    "\n",
    "* The architecture of the network is as follows:\n",
    "    1. Input layer - 28x28 grayscale image (784 neurons + 1 bias neuron at the input layer) \n",
    "    2. Layer 1 - 300 neurons followed by a reLu layer\n",
    "    3. Layer 2 - 100 neurons followed by a reLu layer\n",
    "    4. Layer 3/ Output Layer - 10 neurons where every neuron indicates a class\n",
    "\n",
    "\n",
    "* Points to note:\n",
    "    1. Validation set == Test set for this problem set\n",
    "    2. Use -log(softmax) as the loss function\n",
    "    3. Use GPU if possible\n",
    "    \n",
    "    \n",
    "* Features\n",
    "    1. Classwise accuracy and rankings\n",
    "    2. Which class is hard to predict?\n",
    "    3. Return loss and accuracies for every training step\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # Neural networks module of torch package\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F # Functions such as sigmoid, softmax, cross entropy etc\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_valid = 64\n",
    "seed = 2019\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch insights\n",
    "1. You have dataset class and dataloaders class\n",
    "2. torch.nn.Module is the Base class for all neural network modules. Your models should also subclass this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data - Create dataset class and dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset object\n",
    "dataset = datasets.FashionMNIST(\"../data\", train=True, download=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "# Create a 80%, 20% train, validation split\n",
    "dataset_size = len(dataset)\n",
    "indices = [i for i in range(dataset_size)]\n",
    "\n",
    "# shuffle dataset\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(0.2 * dataset_size))\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# if sampler specified, shuffle should be false for dataloaders\n",
    "# Create dataloaders for train and validation. (Note that test set == validation set in this question)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_train, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_valid, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dims, 300)\n",
    "        self.l2 = nn.Linear(300, 100)\n",
    "        self.l3 = nn.Linear(100, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, 784)\n",
    "        #print(x.size())\n",
    "        # Pass through layer 1 block\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Pass through layer 2 block\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.l3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train Function that includes loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    # Set the module in training mode.\n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Load batch data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the network to determine the output\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss. Here we use Negative log loss (Used for classifying C classes)\n",
    "        # Calculating two losses here. One is the mean of the loss and then the sum of the loss\n",
    "        loss = F.nll_loss(output, target, reduction=\"mean\")\n",
    "        \n",
    "        # Use torch.Tensor.item() to get a Python number from a tensor containing a single value\n",
    "        # reduction = 'sum' to sum up all the batch loss values and add to the running loss\n",
    "        batch_loss = F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "        running_loss += batch_loss\n",
    "        \n",
    "        # Get the number of correctly predicted samples\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        \n",
    "        # View the target tensor as the same size as pred tensor \n",
    "        running_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        # Backpropagate the system the determine the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the paramteres of the model\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    num_samples = float(len(train_loader.sampler))\n",
    "    avg_train_loss = running_loss/num_samples\n",
    "    \n",
    "    print('loss: {:.4f}, accuracy: {}/{} ({:.3f})'.format(\n",
    "        avg_train_loss, running_correct, num_samples,\n",
    "        running_correct / num_samples))\n",
    "        \n",
    "    return avg_train_loss, running_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, valid_loader):\n",
    "    # Set the module in non-training mode.\n",
    "    model.train(False)\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # No need to backpropagate here\n",
    "            running_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            running_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    num_samples = float(len(valid_loader.sampler))\n",
    "    avg_valid_loss = running_loss/num_samples\n",
    "\n",
    "    print('val_loss: {:.4f}, val_accuracy: {}/{} ({:.3f})'.format(\n",
    "        avg_valid_loss, running_correct, num_samples,\n",
    "        running_correct / num_samples))\n",
    "    \n",
    "    return avg_valid_loss, running_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    \n",
    "    clf_matrix = torch.zeros(10, 10)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            running_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            running_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            for t, p in zip(target.view(-1), pred.view(-1)):\n",
    "                clf_matrix[t.long(), p.long()] += 1\n",
    "                \n",
    "    num_samples = float(len(test_loader.sampler))\n",
    "    avg_test_loss = running_loss/num_samples\n",
    "\n",
    "    print('test_loss: {:.4f}, test_accuracy: {}/{} ({:.3f})\\n'.format(\n",
    "        avg_test_loss, running_correct, num_samples,\n",
    "        running_correct / num_samples))\n",
    "    \n",
    "    clf_report = clf_matrix.diag()/clf_matrix.sum(1)\n",
    "    \n",
    "    return avg_test_loss, running_correct/num_samples, clf_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device =  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5164, accuracy: 25113/48000.0 (0.523)\n",
      "val_loss: 0.9399, val_accuracy: 7863/12000.0 (0.655)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▊                                                                                | 1/30 [00:09<04:42,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7874, accuracy: 34333/48000.0 (0.715)\n",
      "val_loss: 0.7010, val_accuracy: 8997/12000.0 (0.750)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▌                                                                             | 2/30 [00:19<04:31,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6399, accuracy: 37226/48000.0 (0.776)\n",
      "val_loss: 0.6204, val_accuracy: 9428/12000.0 (0.786)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▎                                                                          | 3/30 [00:29<04:21,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5671, accuracy: 38595/48000.0 (0.804)\n",
      "val_loss: 0.5577, val_accuracy: 9658/12000.0 (0.805)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|███████████                                                                        | 4/30 [00:39<04:18,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5241, accuracy: 39320/48000.0 (0.819)\n",
      "val_loss: 0.5207, val_accuracy: 9862/12000.0 (0.822)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▊                                                                     | 5/30 [00:50<04:19, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4958, accuracy: 39726/48000.0 (0.828)\n",
      "val_loss: 0.4923, val_accuracy: 9981/12000.0 (0.832)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▌                                                                  | 6/30 [01:02<04:16, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4758, accuracy: 39991/48000.0 (0.833)\n",
      "val_loss: 0.4863, val_accuracy: 9950/12000.0 (0.829)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|███████████████████▎                                                               | 7/30 [01:13<04:07, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4631, accuracy: 40243/48000.0 (0.838)\n",
      "val_loss: 0.4746, val_accuracy: 9986/12000.0 (0.832)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██████████████████████▏                                                            | 8/30 [01:24<03:59, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4513, accuracy: 40388/48000.0 (0.841)\n",
      "val_loss: 0.4629, val_accuracy: 10050/12000.0 (0.838)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▉                                                          | 9/30 [01:35<03:49, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4407, accuracy: 40597/48000.0 (0.846)\n",
      "val_loss: 0.4587, val_accuracy: 10080/12000.0 (0.840)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████████████████▎                                                      | 10/30 [01:46<03:41, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4325, accuracy: 40756/48000.0 (0.849)\n",
      "val_loss: 0.4505, val_accuracy: 10156/12000.0 (0.846)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|██████████████████████████████                                                    | 11/30 [01:58<03:34, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4256, accuracy: 40888/48000.0 (0.852)\n",
      "val_loss: 0.4647, val_accuracy: 10073/12000.0 (0.839)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▊                                                 | 12/30 [02:09<03:21, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4171, accuracy: 40975/48000.0 (0.854)\n",
      "val_loss: 0.4387, val_accuracy: 10149/12000.0 (0.846)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|███████████████████████████████████▌                                              | 13/30 [02:20<03:10, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4101, accuracy: 41154/48000.0 (0.857)\n",
      "val_loss: 0.4261, val_accuracy: 10256/12000.0 (0.855)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|██████████████████████████████████████▎                                           | 14/30 [02:32<03:02, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4037, accuracy: 41244/48000.0 (0.859)\n",
      "val_loss: 0.4216, val_accuracy: 10267/12000.0 (0.856)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████                                         | 15/30 [02:44<02:51, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3978, accuracy: 41334/48000.0 (0.861)\n",
      "val_loss: 0.4179, val_accuracy: 10269/12000.0 (0.856)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████▋                                      | 16/30 [02:55<02:39, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3914, accuracy: 41439/48000.0 (0.863)\n",
      "val_loss: 0.4182, val_accuracy: 10280/12000.0 (0.857)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|██████████████████████████████████████████████▍                                   | 17/30 [03:07<02:29, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3866, accuracy: 41479/48000.0 (0.864)\n",
      "val_loss: 0.4058, val_accuracy: 10310/12000.0 (0.859)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▏                                | 18/30 [03:18<02:17, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3812, accuracy: 41626/48000.0 (0.867)\n",
      "val_loss: 0.4009, val_accuracy: 10334/12000.0 (0.861)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|███████████████████████████████████████████████████▉                              | 19/30 [03:31<02:10, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3759, accuracy: 41729/48000.0 (0.869)\n",
      "val_loss: 0.4089, val_accuracy: 10306/12000.0 (0.859)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 20/30 [03:43<02:00, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3703, accuracy: 41758/48000.0 (0.870)\n",
      "val_loss: 0.4005, val_accuracy: 10317/12000.0 (0.860)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 21/30 [03:58<01:56, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3662, accuracy: 41827/48000.0 (0.871)\n",
      "val_loss: 0.3988, val_accuracy: 10350/12000.0 (0.863)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|████████████████████████████████████████████████████████████▏                     | 22/30 [04:10<01:40, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3629, accuracy: 41876/48000.0 (0.872)\n",
      "val_loss: 0.3894, val_accuracy: 10340/12000.0 (0.862)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|██████████████████████████████████████████████████████████████▊                   | 23/30 [04:22<01:25, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3581, accuracy: 41961/48000.0 (0.874)\n",
      "val_loss: 0.3808, val_accuracy: 10407/12000.0 (0.867)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 24/30 [04:33<01:12, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3538, accuracy: 42034/48000.0 (0.876)\n",
      "val_loss: 0.3885, val_accuracy: 10354/12000.0 (0.863)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 25/30 [04:47<01:02, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3496, accuracy: 42086/48000.0 (0.877)\n",
      "val_loss: 0.3863, val_accuracy: 10390/12000.0 (0.866)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|███████████████████████████████████████████████████████████████████████           | 26/30 [04:59<00:49, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3472, accuracy: 42150/48000.0 (0.878)\n",
      "val_loss: 0.3749, val_accuracy: 10415/12000.0 (0.868)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 27/30 [05:11<00:36, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3418, accuracy: 42234/48000.0 (0.880)\n",
      "val_loss: 0.3691, val_accuracy: 10439/12000.0 (0.870)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▌     | 28/30 [05:23<00:24, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3371, accuracy: 42323/48000.0 (0.882)\n",
      "val_loss: 0.3726, val_accuracy: 10457/12000.0 (0.871)\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▎  | 29/30 [05:36<00:12, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3340, accuracy: 42310/48000.0 (0.881)\n",
      "val_loss: 0.3679, val_accuracy: 10455/12000.0 (0.871)\n",
      "Saving best model\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [05:48<00:00, 12.42s/it]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(\"Available device = \", device)\n",
    "model = SimpleNN(input_dims=28*28).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# training and validation history\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "\n",
    "best_val_loss = 1.0\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    tr_loss, tr_acc = train(model, device, train_loader, optimizer)\n",
    "    val_loss, val_acc = validation(model, device, valid_loader)\n",
    "    loss_hist.append((tr_loss, val_loss))\n",
    "    acc_hist.append((tr_acc, val_acc))\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(\"Saving best model\")\n",
    "        torch.save(model.state_dict(), \"model\")\n",
    "    print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "xi = [i for i in range(0, len(loss_hist), 2)]\n",
    "plt.plot([i[0] for i in loss_hist], label = \"Training Loss\")\n",
    "plt.plot([i[1] for i in loss_hist], label = \"Validation Loss\")\n",
    "plt.xticks(xi)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "xi = [i for i in range(0, len(loss_hist), 2)]\n",
    "plt.plot([i[0] for i in acc_hist], label = \"Training Accuracy\")\n",
    "plt.plot([i[1] for i in acc_hist], label = \"Validation Accuracy\")\n",
    "plt.xticks(xi)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best saved weights\n",
    "model = SimpleNN(input_dims=28*28).to(device)\n",
    "model.load_state_dict(torch.load(\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set which is the validation set\n",
    "test_loss, test_acc, clf_report = test(model, device, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy based on test set (which is the validation set in our case) = 0.871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-Wise Accuracy Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_CLOTHING = {0 :'T-shirt/top',\n",
    "                  1 :'Trouser',\n",
    "                  2 :'Pullover',\n",
    "                  3 :'Dress',\n",
    "                  4 :'Coat',\n",
    "                  5 :'Sandal',\n",
    "                  6 :'Shirt',\n",
    "                  7 :'Sneaker',\n",
    "                  8 :'Bag',\n",
    "                  9 :'Ankle boot'}\n",
    "\n",
    "# Create dictionary of class and accuracy\n",
    "class_wise_acc = dict()\n",
    "for i in range(len(clf_report)):\n",
    "    class_wise_acc[CLASS_CLOTHING[i]] = clf_report[i].item()\n",
    "\n",
    "class_wise_acc = dict(sorted(class_wise_acc.items(), key=lambda x: x[1]))\n",
    "plt.bar(range(len(class_wise_acc)), list(class_wise_acc.values()), align='center')\n",
    "plt.xticks(range(len(class_wise_acc)), list(class_wise_acc.keys()), rotation = 60)\n",
    "plt.title(\"Classification Accuracy per class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the classification report, **Shirt** is the most difficult class to predict.\n",
    "Ranking of classes based on accuracies is clearly shown in the bar chart above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
